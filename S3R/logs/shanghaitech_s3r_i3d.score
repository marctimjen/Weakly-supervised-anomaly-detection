
**********
!!python/object:anomaly.apis.opts.S3RArgumentParser
version: vad-ws-0.2
feature_size: 2048
workers: 0
model_name: s3r
max_epoch: 15000
evaluate_min_step: 5000
gpus: 1
lr: 0.001
inference: false
dictionary_path: !!python/object/apply:pathlib.PosixPath
- dictionary
dropout: 0.7
debug: false
root_path: !!python/object/apply:pathlib.PosixPath
- data
seed: 823
dataset: shanghaitech
report_k: 10
backbone: i3d
batch_size: 32
quantize_size: 32
resume: null
descr:
- S3R
- video
- anomaly
- detection
evaluate_freq: 1
checkpoint_path: !!python/object/apply:pathlib.PosixPath
- checkpoint
log_path: !!python/object/apply:pathlib.PosixPath
- logs
plot_freq: 10



PyTorch version: 1.6.0
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 18.04.6 LTS
GCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010
CMake version: version 3.16.3

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 2080 Ti
GPU 1: NVIDIA GeForce RTX 2080 Ti

Nvidia driver version: 470.103.01
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip3] numpy==1.19.2
[pip3] torch==1.6.0
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.1.243             h6bb024c_0  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he8ac12f_0  
[conda] mkl_fft                   1.3.0            py36h54f3939_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] numpy                     1.19.2           py36h54aff64_0  
[conda] numpy-base                1.19.2           py36hfa32c7d_0  
[conda] pytorch                   1.6.0           py3.6_cuda10.1.243_cudnn7.6.3_0    pytorch
**********

==========
S3R(
  (video_embedding): Sequential(
    (0): Aggregate(
      (conv_1): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        (1): GroupNorm(8, 512, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (conv_2): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
        (1): GroupNorm(8, 512, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (conv_3): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
        (1): GroupNorm(8, 512, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (conv_4): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)
        (1): ReLU()
      )
      (conv_5): Sequential(
        (0): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
        (1): GroupNorm(8, 2048, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (non_local): NonLocalBlock1D(
        (value): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
        (alter): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (query): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
        (key): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
    )
    (1): Dropout(p=0.7, inplace=False)
  )
  (macro_embedding): Sequential(
    (0): Aggregate(
      (conv_1): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        (1): GroupNorm(8, 512, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (conv_2): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
        (1): GroupNorm(8, 512, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (conv_3): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
        (1): GroupNorm(8, 512, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (conv_4): Sequential(
        (0): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)
        (1): ReLU()
      )
      (conv_5): Sequential(
        (0): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
        (1): GroupNorm(8, 2048, eps=1e-05, affine=True)
        (2): ReLU()
      )
      (non_local): NonLocalBlock1D(
        (value): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
        (alter): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (query): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
        (key): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
      )
    )
    (1): Dropout(p=0.7, inplace=False)
  )
  (en_normal): enNormal(
    (en_normal_module): enNormalModule(
      (query_embedding): Linear(in_features=2048, out_features=512, bias=True)
      (cache_embedding): Linear(in_features=2048, out_features=512, bias=True)
      (value_embedding): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (de_normal): deNormal(
    (channel_attention): ChannelAttention(
      (channel_gate): ChannelGate(
        (mlp): Sequential(
          (0): Flatten()
          (1): Linear(in_features=2048, out_features=128, bias=True)
          (2): ReLU()
          (3): Linear(in_features=128, out_features=2048, bias=True)
        )
      )
    )
  )
  (video_projection): Sequential(
    (0): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))
    (1): GroupNorm(8, 2048, eps=1e-05, affine=True)
    (2): ReLU()
  )
  (macro_projection): Sequential(
    (0): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(1,))
    (1): GroupNorm(8, 2048, eps=1e-05, affine=True)
    (2): ReLU()
  )
  (video_classifier): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.7, inplace=False)
    (3): Linear(in_features=512, out_features=128, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.7, inplace=False)
    (6): Linear(in_features=128, out_features=1, bias=True)
    (7): Sigmoid()
  )
  (macro_classifier): GlobalStatistics(
    (flat): Flatten()
    (mlp): Sequential(
      (0): Linear(in_features=2048, out_features=512, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.7, inplace=False)
      (3): Linear(in_features=512, out_features=128, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.7, inplace=False)
      (6): Linear(in_features=128, out_features=1, bias=True)
    )
  )
  (drop_out): Dropout(p=0.7, inplace=False)
)
==========


    [1m[35mVideo Anomaly Detection[0m
        - dataset:	 [4m[1m[37mshanghaitech[0m
        - version:	 vad-ws-0.2
        - description:	 [1m[32mS3R video anomaly detection[0m
        - initial AUC score: 44.660 %
        - initial learning rate: 0.0010
    
+-------------------------------------------------------------------------------------------------------+
|  Step  |   AUC    |  Training loss  |          Elapsed time          |              Now               |
---------------------------------------------------------------------------------------------------------
|  5001  |  75.170  |      0.342      |         1:23:50.816391         |      2022-07-06 15:32:32       | 
|  5003  |  75.616  |      0.330      |         1:23:59.505096         |      2022-07-06 15:32:41       | 
|  5004  |  93.448  |      0.362      |         1:24:04.481931         |      2022-07-06 15:32:46       | 
|  5005  |  93.767  |      0.354      |         1:24:09.401269         |      2022-07-06 15:32:51       | 
|  5006  |  95.873  |      0.374      |         1:24:14.704321         |      2022-07-06 15:32:56       | 
|  5007  |  96.388  |      0.331      |         1:24:19.647818         |      2022-07-06 15:33:01       | 
|  5008  |  96.641  |      0.312      |         1:24:24.517178         |      2022-07-06 15:33:06       | 
|  5112  |  96.695  |      0.281      |         1:30:48.641970         |      2022-07-06 15:39:30       | 
|  5284  |  96.729  |      0.327      |         1:41:24.640624         |      2022-07-06 15:50:06       | 
|  5286  |  96.960  |      0.300      |         1:41:33.659433         |      2022-07-06 15:50:15       | 
|  5287  |  97.227  |      0.294      |         1:41:38.767043         |      2022-07-06 15:50:20       | 
|  5288  |  97.237  |      0.272      |         1:41:44.951842         |      2022-07-06 15:50:26       | 
|  6721  |  97.319  |      0.316      |         3:09:32.193686         |      2022-07-06 17:18:13       | 
|  6723  |  97.366  |      0.324      |         3:09:40.913002         |      2022-07-06 17:18:22       | 
|  8645  |  97.395  |      0.280      |         5:07:24.266722         |      2022-07-06 19:16:06       | 
+-------------------------------------------------------------------------------------------------------+
